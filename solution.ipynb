{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torchvision\nfrom torchvision import transforms, models\nfrom torch.utils.data import Dataset\nfrom PIL import Image\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nimport zipfile\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","editable":false,"execution":{"iopub.status.busy":"2021-11-23T05:52:03.332187Z","iopub.execute_input":"2021-11-23T05:52:03.333091Z","iopub.status.idle":"2021-11-23T05:52:05.180005Z","shell.execute_reply.started":"2021-11-23T05:52:03.332938Z","shell.execute_reply":"2021-11-23T05:52:05.178941Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"data_root = '../working/plates/'","metadata":{"execution":{"iopub.status.busy":"2021-11-23T05:52:05.182428Z","iopub.execute_input":"2021-11-23T05:52:05.182694Z","iopub.status.idle":"2021-11-23T05:52:05.189594Z","shell.execute_reply.started":"2021-11-23T05:52:05.182663Z","shell.execute_reply":"2021-11-23T05:52:05.188224Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"os.getcwd()","metadata":{"editable":false,"execution":{"iopub.status.busy":"2021-11-23T05:52:05.191668Z","iopub.execute_input":"2021-11-23T05:52:05.192321Z","iopub.status.idle":"2021-11-23T05:52:05.206317Z","shell.execute_reply.started":"2021-11-23T05:52:05.192273Z","shell.execute_reply":"2021-11-23T05:52:05.204422Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"print(os.listdir(\"../input/platesv2\"))","metadata":{"editable":false,"execution":{"iopub.status.busy":"2021-11-23T05:52:05.207824Z","iopub.execute_input":"2021-11-23T05:52:05.208758Z","iopub.status.idle":"2021-11-23T05:52:05.221171Z","shell.execute_reply.started":"2021-11-23T05:52:05.208710Z","shell.execute_reply":"2021-11-23T05:52:05.219718Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"with zipfile.ZipFile('../input/platesv2/plates.zip', 'r') as zip_obj:\n   # Extract all the contents of zip file in current directory\n   zip_obj.extractall('/kaggle/working/')\n    \nprint('After zip extraction:')\nprint(os.listdir(\"/kaggle/working/\"))","metadata":{"editable":false,"execution":{"iopub.status.busy":"2021-11-23T05:52:05.224251Z","iopub.execute_input":"2021-11-23T05:52:05.224608Z","iopub.status.idle":"2021-11-23T05:52:07.132801Z","shell.execute_reply.started":"2021-11-23T05:52:05.224565Z","shell.execute_reply":"2021-11-23T05:52:07.131654Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"img_folder = \"/kaggle/working/plates\"\ntrain_folder = 'train'\ntest_folder = 'test'\nos.listdir(os.path.join(img_folder, train_folder))","metadata":{"editable":false,"execution":{"iopub.status.busy":"2021-11-23T05:52:07.141632Z","iopub.execute_input":"2021-11-23T05:52:07.145407Z","iopub.status.idle":"2021-11-23T05:52:07.159704Z","shell.execute_reply.started":"2021-11-23T05:52:07.144346Z","shell.execute_reply":"2021-11-23T05:52:07.158134Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"f = 100\n# transforms.ColorJitter(brightness=0, contrast=0, saturation=0, hue=0)\ntrain_transforms_big = [transforms.Compose([\n    transforms.CenterCrop(f),\n    transforms.RandomHorizontalFlip(),\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n]),\ntransforms.Compose([\n    transforms.CenterCrop(f),\n    transforms.Resize((224, 224)),\n    transforms.RandomVerticalFlip(),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n]),\ntransforms.Compose([\n    transforms.RandomRotation(50),\n    transforms.CenterCrop(f),\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n]),\ntransforms.Compose([\n    transforms.RandomVerticalFlip(),\n    transforms.RandomHorizontalFlip(),\n    transforms.CenterCrop(f),\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n]),\ntransforms.Compose([\n    transforms.RandomVerticalFlip(),\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomRotation(50),\n    transforms.CenterCrop(f),\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n]),\ntransforms.Compose([\n    transforms.CenterCrop(f),\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n]),\ntransforms.Compose([\n    transforms.RandomPerspective(distortion_scale=0.09, p=0.75, interpolation=3, fill=255),\n    transforms.CenterCrop(f),\n    transforms.Resize((224, 224)),\n    transforms.RandomHorizontalFlip(),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n]),\ntransforms.Compose([\n    transforms.RandomPerspective(distortion_scale=0.09, p=0.75, interpolation=3, fill=255),\n    transforms.CenterCrop(f),\n    transforms.Resize((224, 224)),\n    transforms.RandomVerticalFlip(),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n]),\ntransforms.Compose([\n    transforms.RandomPerspective(distortion_scale=0.09, p=0.75, interpolation=3, fill=255),\n    transforms.RandomRotation(50),\n    transforms.CenterCrop(f),\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n]),\ntransforms.Compose([\n    transforms.RandomPerspective(distortion_scale=0.09, p=0.75, interpolation=3, fill=255),\n    transforms.RandomVerticalFlip(),\n    transforms.RandomHorizontalFlip(),\n    transforms.CenterCrop(f),\n    transforms.Resize((224, 224)),\n    #transforms.RandomRotation(50),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n]),\ntransforms.Compose([\n    transforms.RandomPerspective(distortion_scale=0.09, p=0.75, interpolation=3, fill=255),\n    transforms.RandomVerticalFlip(),\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomRotation(50),\n    transforms.CenterCrop(f),\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n]),\ntransforms.Compose([\n    transforms.RandomPerspective(distortion_scale=0.09, p=0.75, interpolation=3, fill=255),\n    transforms.CenterCrop(f),\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n]),\ntransforms.Compose([\n    transforms.RandomPerspective(distortion_scale=0.09, p=0.75, interpolation=3, fill=255),\n    transforms.Resize((224, 224)),    \n    transforms.ColorJitter(hue=(-0.5,0.5)),\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomVerticalFlip(), \n    transforms.ToTensor(), \n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n])\n]","metadata":{"execution":{"iopub.status.busy":"2021-11-23T05:55:57.435108Z","iopub.execute_input":"2021-11-23T05:55:57.436086Z","iopub.status.idle":"2021-11-23T05:55:57.492737Z","shell.execute_reply.started":"2021-11-23T05:55:57.436035Z","shell.execute_reply":"2021-11-23T05:55:57.491840Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"class CleanDirtyDataset(Dataset):\n    def __init__(self, file_list, file_dir, mode, transform):\n        self.file_list = file_list\n        self.file_dir = file_dir\n        self.mode = mode\n        self.transform = transform\n        \n        if mode == 'train':\n            if 'clean' in self.file_dir:\n                self.label = 1 # clean label \n            else:\n                self.label = 0 # dirty label\n    \n    def __len__(self):\n        return len(self.file_list)\n    \n    def __getitem__(self, idx):\n        img = Image.open(os.path.join(self.file_dir, self.file_list[idx]))\n        if self.transform:\n            img = self.transform(img)\n        if self.mode == 'train':\n            img = img.numpy()\n            return img.astype('float32'), self.label\n        else:\n            img = img.numpy()\n            return img.astype('float32'), self.file_list[idx]\n        \n\ntest_transforms = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(), \n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n])","metadata":{"editable":false,"execution":{"iopub.status.busy":"2021-11-23T05:56:04.859361Z","iopub.execute_input":"2021-11-23T05:56:04.859667Z","iopub.status.idle":"2021-11-23T05:56:04.872363Z","shell.execute_reply.started":"2021-11-23T05:56:04.859623Z","shell.execute_reply":"2021-11-23T05:56:04.871119Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"dirty_folder = os.path.join(img_folder, train_folder, 'dirty')\nclean_folder = os.path.join(img_folder, train_folder, 'cleaned')\ndirty = [f for f in os.listdir(dirty_folder) if '.jpg' in f]\nclean = [f for f in os.listdir(clean_folder) if '.jpg' in f]","metadata":{"editable":false,"execution":{"iopub.status.busy":"2021-11-23T05:56:15.198245Z","iopub.execute_input":"2021-11-23T05:56:15.198565Z","iopub.status.idle":"2021-11-23T05:56:15.205604Z","shell.execute_reply.started":"2021-11-23T05:56:15.198534Z","shell.execute_reply":"2021-11-23T05:56:15.204081Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import ConcatDataset\nfrom torch.utils.data import DataLoader\n\nclean_img_big = [CleanDirtyDataset(file_list=clean, \n                                   file_dir=clean_folder, \n                                   mode='train', \n                                   transform=transform) for transform in train_transforms_big]\ndirty_img_big = [CleanDirtyDataset(file_list=dirty, \n                                   file_dir=dirty_folder, \n                                   mode='train', \n                                   transform=transform) for transform in train_transforms_big]\n\ntrain_data_big = ConcatDataset(clean_img_big + dirty_img_big)\n\ndataloader = DataLoader(train_data_big, batch_size=32, shuffle=True, num_workers=4)","metadata":{"execution":{"iopub.status.busy":"2021-11-23T06:02:08.014985Z","iopub.execute_input":"2021-11-23T06:02:08.015365Z","iopub.status.idle":"2021-11-23T06:02:08.025785Z","shell.execute_reply.started":"2021-11-23T06:02:08.015330Z","shell.execute_reply":"2021-11-23T06:02:08.024635Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nsamples, labels = iter(dataloader).next()\nplt.figure(figsize=(16,24))\ngrid_imgs = torchvision.utils.make_grid(samples[:24])\nnp_grid_imgs = grid_imgs.numpy()\n# in tensor, image is (batch, width, height), so you have to transpose it to (width, height, batch) in numpy to show it.\nplt.imshow(np.transpose(np_grid_imgs, (1,2,0)))","metadata":{"execution":{"iopub.status.busy":"2021-11-23T06:02:11.458494Z","iopub.execute_input":"2021-11-23T06:02:11.458991Z","iopub.status.idle":"2021-11-23T06:02:13.630490Z","shell.execute_reply.started":"2021-11-23T06:02:11.458955Z","shell.execute_reply":"2021-11-23T06:02:13.626894Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"from torchvision import models\n\ndevice = \"cuda\"\n\nmodel_res = models.resnet152(pretrained=True)\n\nfor param in model_res.parameters(): \n    param.requires_grad = False \n    \nmodel_res.fc = torch.nn.Sequential(\n    torch.nn.Linear(model_res.fc.in_features, 500),\n    torch.nn.Linear(500, 2)\n)\nmodel_res = model_res.to(device)\n\nloss = torch.nn.CrossEntropyLoss()\n\noptimizer_sgd = torch.optim.SGD(model_res.parameters(), lr=0.01, momentum=0.95)\nscheduler = torch.optim.lr_scheduler.StepLR(optimizer_sgd, step_size=7, gamma=0.1)","metadata":{"execution":{"iopub.status.busy":"2021-11-23T06:11:01.319880Z","iopub.execute_input":"2021-11-23T06:11:01.320197Z","iopub.status.idle":"2021-11-23T06:11:05.993185Z","shell.execute_reply.started":"2021-11-23T06:11:01.320163Z","shell.execute_reply":"2021-11-23T06:11:05.992161Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"model = torchvision.models.densenet121(pretrained=True)\n\nfor param in model.parameters(): \n    param.requires_grad = False \n    \nmodel.classifier = torch.nn.Sequential(\n    torch.nn.Linear(model.classifier.in_features, 500),\n    torch.nn.Linear(500, 2)\n)\nmodel = model.to(device)\n\nloss = torch.nn.CrossEntropyLoss()\n\noptimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\nscheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)","metadata":{"execution":{"iopub.status.busy":"2021-11-23T06:11:59.477655Z","iopub.execute_input":"2021-11-23T06:11:59.478242Z","iopub.status.idle":"2021-11-23T06:11:59.826074Z","shell.execute_reply.started":"2021-11-23T06:11:59.478199Z","shell.execute_reply":"2021-11-23T06:11:59.825057Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"epochs = 50\ni = 1\ncheck = len(dataloader) // 4\nmodel.train()\ntotal_loss = 0\nloss_list = []\nacc_list = []\n\nfor epoch in range(epochs):\n    for imgs, labels in dataloader:\n        imgs, labels = imgs.to(device), labels.to(device)\n        optimizer.zero_grad()\n        predict = model(imgs)\n        loss_predict = loss(predict, labels)\n        loss_predict.backward()\n        optimizer.step()\n        total_loss += loss_predict.item()\n        scheduler.step()\n        \n        if i % check == 0:\n            pred = torch.argmax(predict, dim=1)\n            correct = pred.eq(labels)\n            acc = torch.mean(correct.float())\n            print(f'Epoch: {epoch}, loss: {total_loss}, acc: {acc}')\n            loss_list.append(total_loss)\n            acc_list.append(acc / check)\n            total_loss = 0\n        i += 1","metadata":{"execution":{"iopub.status.busy":"2021-11-23T06:12:42.576652Z","iopub.execute_input":"2021-11-23T06:12:42.577059Z","iopub.status.idle":"2021-11-23T06:16:44.193623Z","shell.execute_reply.started":"2021-11-23T06:12:42.576996Z","shell.execute_reply":"2021-11-23T06:16:44.192408Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"plt.plot(loss_list)\nplt.show()\nplt.plot(acc_list)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-11-23T06:16:44.196283Z","iopub.execute_input":"2021-11-23T06:16:44.196568Z","iopub.status.idle":"2021-11-23T06:16:44.652374Z","shell.execute_reply.started":"2021-11-23T06:16:44.196535Z","shell.execute_reply":"2021-11-23T06:16:44.651345Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"test_transforms = {\n                      'Вырезать в центре квадрат со стороной 140 ': transforms.Compose([\n    transforms.CenterCrop(140),\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(), \n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n]),\n                     'Вырезать в центре квадрат со стороной 135': transforms.Compose([\n    transforms.CenterCrop(135),\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(), \n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n]), \n                      'Вырезать в центре квадрат со стороной 130': transforms.Compose([\n    transforms.CenterCrop(130),\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(), \n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n]),\n                      'Вырезать в центре квадрат со стороной 125': transforms.Compose([\n    transforms.CenterCrop(125),\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(), \n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n]),\n                      'Вырезать в центре квадрат со стороной 120': transforms.Compose([\n    transforms.CenterCrop(120),\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(), \n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n]),\n                      'Вырезать в центре квадрат со стороной 115': transforms.Compose([\n    transforms.CenterCrop(115),\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(), \n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n]),\n                      'Вырезать в центре квадрат со стороной 110': transforms.Compose([\n    transforms.CenterCrop(110),\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(), \n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n]),\n                      'Вырезать в центре квадрат со стороной 105': transforms.Compose([\n    transforms.CenterCrop(105),\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(), \n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n]),\n                      'Вырезать в центре квадрат со стороной 100': transforms.Compose([\n    transforms.CenterCrop(100),\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(), \n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n]),\n                     'Вырезать в центре квадрат со стороной 95': transforms.Compose([\n    transforms.CenterCrop(95),\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(), \n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n]),\n                       'Вырезать в центре квадрат со стороной 90': transforms.Compose([\n    transforms.CenterCrop(90),\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(), \n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n]),\n                       'Вырезать в центре квадрат со стороной 85': transforms.Compose([\n    transforms.CenterCrop(85),\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(), \n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n]),\n                       'Вырезать в центре квадрат со стороной 80': transforms.Compose([\n    transforms.CenterCrop(80),\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(), \n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n]),\n                      'Вырезать в центре квадрат со стороной 75': transforms.Compose([\n    transforms.CenterCrop(75),\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(), \n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n]),                                         \n                       'Вырезать в центре квадрат со стороной 70': transforms.Compose([\n    transforms.CenterCrop(70),\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(), \n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n]),                                                           \n                     }","metadata":{"editable":false,"execution":{"iopub.status.busy":"2021-11-23T06:17:49.208733Z","iopub.execute_input":"2021-11-23T06:17:49.209090Z","iopub.status.idle":"2021-11-23T06:17:49.236404Z","shell.execute_reply.started":"2021-11-23T06:17:49.209055Z","shell.execute_reply":"2021-11-23T06:17:49.234025Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"import shutil\nfrom tqdm import tqdm","metadata":{"editable":false,"execution":{"iopub.status.busy":"2021-11-23T06:17:51.731248Z","iopub.execute_input":"2021-11-23T06:17:51.731585Z","iopub.status.idle":"2021-11-23T06:17:51.736897Z","shell.execute_reply.started":"2021-11-23T06:17:51.731528Z","shell.execute_reply":"2021-11-23T06:17:51.735683Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"batch_size = 10","metadata":{"execution":{"iopub.status.busy":"2021-11-23T06:17:56.290591Z","iopub.execute_input":"2021-11-23T06:17:56.291115Z","iopub.status.idle":"2021-11-23T06:17:56.296386Z","shell.execute_reply.started":"2021-11-23T06:17:56.291080Z","shell.execute_reply":"2021-11-23T06:17:56.295048Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"img_folder","metadata":{"execution":{"iopub.status.busy":"2021-11-23T06:18:00.033952Z","iopub.execute_input":"2021-11-23T06:18:00.034488Z","iopub.status.idle":"2021-11-23T06:18:00.042099Z","shell.execute_reply.started":"2021-11-23T06:18:00.034452Z","shell.execute_reply":"2021-11-23T06:18:00.040894Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"test_folder = os.path.join(img_folder, 'test')\ntest_imgs = [f for f in os.listdir(test_folder) if '.jpg' in f]","metadata":{"execution":{"iopub.status.busy":"2021-11-23T06:18:02.272459Z","iopub.execute_input":"2021-11-23T06:18:02.272761Z","iopub.status.idle":"2021-11-23T06:18:02.279975Z","shell.execute_reply.started":"2021-11-23T06:18:02.272730Z","shell.execute_reply":"2021-11-23T06:18:02.278742Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"df = pd.DataFrame\n# Для увеличения точности, необходимо предсказать результаты по разным вырезкам из изображения. \n# Вполне может случиться, что на меньшем изображении нет грязи, а на большем есть. \n# Тогда усреднение поможет исправить ситуацию.\n\nfor (_, transforms) in test_transforms.items():\n    test_folder = os.path.join(img_folder, test_folder)\n    test_imgs = [f for f in os.listdir(test_folder) if '.jpg' in f]\n    test_data = CleanDirtyDataset(file_list=test_imgs, file_dir=test_folder, mode='test', transform=transforms)\n    testloader = DataLoader(test_data, batch_size=4, shuffle=False, num_workers=4)\n\n    model.eval()\n\n    file_names = []\n    res = []\n\n    for x, fn in tqdm(testloader):\n        with torch.no_grad():\n            x = x.to(device)\n            output = model(x)\n    #         print(output)\n#             pred = torch.argmax(output, dim=1)\n    #         print(pred)\n            file_names += fn\n            res.append(torch.nn.functional.softmax(output, dim=1)[:,1].data.cpu().numpy())\n#     test_folder = os.path.join(img_folder, test_folder)\n#     test_imgs = [f for f in os.listdir(test_folder) if '.jpg' in f]\n#     test_data = CleanDirtyDataset(file_list=test_imgs, file_dir=test_folder, mode='test', transform=transforms)\n#     testloader = DataLoader(test_data, batch_size=4, shuffle=False, num_workers=4)\n#     # Переводим модель в состояние eval \n#     model.eval()\n# #     test_predictions = []  \n# #     test_img_paths = [] \n#     # И предсказываем результаты\n# #     for inputs, labels in tqdm(test_dataloader):\n# #         inputs = inputs.to(device) \n# #         test_img_path.append(labels)\n# #         with torch.set_grad_enabled(False):\n# #             preds = model(inputs) \n# #         test_predictions.append(\n# #             torch.nn.functional.softmax(preds, dim=1)[:,1].data.cpu().numpy())\n# # #         test_img_paths.extend(paths)\n# #     test_predictions = np.concatenate(test_predictions)\n    \n# #     # Записываем результаты\n# #     submission_df = pd.DataFrame.from_dict({'id': test_img_paths, 'label': test_predictions})\n# # #     submission_df['id'] = submission_df['id']\n# # #     submission_df['id'] = submission_df['id'].str.replace('.jpg', '')\n# #     submission_df.set_index('id', inplace=True)\n#     ###\n#     file_names = []\n#     res = []\n\n#     for x, fn in testloader:\n#         with torch.no_grad():\n#             x = x.to(device)\n#             output = model(x)\n#     #         print(output)\n#             pred = torch.argmax(output, dim=1)\n#     #         print(pred)\n#             file_names += fn\n#             res.append(torch.nn.functional.softmax(pred, dim=1)[:,1].data.cpu().numpy())\n\n    img_id = [i.split('.')[0] for i in file_names]\n    res = np.concatenate(res)\n    final = pd.DataFrame({'id': img_id, 'label': res})\n\n#     final['label'] = final['label'].map(lambda pred: 'dirty' if pred < 0.5 else 'cleaned')\n    final.set_index('id', inplace=True)\n    ###\n    \n    try : df = df.merge(final, how='inner', on='id') \n        \n    # Для первой итерации\n    except BaseException: \n        df = final \ndf.head(8)","metadata":{"execution":{"iopub.status.busy":"2021-11-23T06:18:04.343930Z","iopub.execute_input":"2021-11-23T06:18:04.344580Z","iopub.status.idle":"2021-11-23T06:20:03.235389Z","shell.execute_reply.started":"2021-11-23T06:18:04.344544Z","shell.execute_reply":"2021-11-23T06:20:03.233408Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"df.shape","metadata":{"execution":{"iopub.status.busy":"2021-11-23T06:20:03.238322Z","iopub.execute_input":"2021-11-23T06:20:03.238739Z","iopub.status.idle":"2021-11-23T06:20:03.246445Z","shell.execute_reply.started":"2021-11-23T06:20:03.238664Z","shell.execute_reply":"2021-11-23T06:20:03.245150Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"len(test_transforms)","metadata":{"execution":{"iopub.status.busy":"2021-11-23T06:20:03.248480Z","iopub.execute_input":"2021-11-23T06:20:03.248878Z","iopub.status.idle":"2021-11-23T06:20:03.261892Z","shell.execute_reply.started":"2021-11-23T06:20:03.248814Z","shell.execute_reply":"2021-11-23T06:20:03.260512Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"new_df = df.copy(deep=True)\nnew_df['mean'] = new_df.mean(axis=1)\nnew_df.drop(new_df.columns[:-1], axis='columns', inplace=True)\nnew_df['label'] = new_df['mean'].map(lambda pred: 'dirty' if pred < 0.50 else 'cleaned')\nnew_df.drop(new_df.columns[:-1], axis='columns', inplace=True)\nnew_df.head(13)","metadata":{"execution":{"iopub.status.busy":"2021-11-23T06:20:03.264631Z","iopub.execute_input":"2021-11-23T06:20:03.265414Z","iopub.status.idle":"2021-11-23T06:20:03.289080Z","shell.execute_reply.started":"2021-11-23T06:20:03.265367Z","shell.execute_reply":"2021-11-23T06:20:03.287920Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"new_df.to_csv('submission.csv')","metadata":{"execution":{"iopub.status.busy":"2021-11-23T06:20:03.292062Z","iopub.execute_input":"2021-11-23T06:20:03.292795Z","iopub.status.idle":"2021-11-23T06:20:03.303046Z","shell.execute_reply.started":"2021-11-23T06:20:03.292751Z","shell.execute_reply":"2021-11-23T06:20:03.302102Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"new_df.set_index('id', inplace =True)","metadata":{"execution":{"iopub.status.busy":"2021-11-18T10:05:47.121102Z","iopub.execute_input":"2021-11-18T10:05:47.12136Z","iopub.status.idle":"2021-11-18T10:05:47.126513Z","shell.execute_reply.started":"2021-11-18T10:05:47.121331Z","shell.execute_reply":"2021-11-18T10:05:47.125515Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_transforms = transforms.Compose([\n    transforms.CenterCrop(85),\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(), \n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n])\ntest_folder = os.path.join(img_folder, test_folder)\ntest_imgs = [f for f in os.listdir(test_folder) if '.jpg' in f]\ntest_data = CleanDirtyDataset(file_list=test_imgs, file_dir=test_folder, mode='test', transform=test_transforms)\ntestloader = DataLoader(test_data, batch_size=4, shuffle=False, num_workers=4)\n\nmodel.eval()\n\nfile_names = []\nres = []\n\nfor x, fn in tqdm(testloader):\n    with torch.no_grad():\n        x = x.to(device)\n        output = model(x)\n#         print(output)\n        pred = torch.argmax(output, dim=1)\n#         print(pred)\n        file_names += [n[:-4] for n in fn]\n        res += [p.item() for p in pred]\n\n# img_id = [i.split()[0] for i in file_names]\n# final = pd.DataFrame({'id': img_id, 'label': res})\n\n# final['label'] = final['label'].map(lambda pred: 'dirty' if pred < 0.5 else 'cleaned')\n# final.set_index('id', inplace=True)\n\n# final.to_csv('submission.csv')\n\n","metadata":{"execution":{"iopub.status.busy":"2021-11-18T09:34:04.222397Z","iopub.execute_input":"2021-11-18T09:34:04.222726Z","iopub.status.idle":"2021-11-18T09:34:10.500538Z","shell.execute_reply.started":"2021-11-18T09:34:04.222696Z","shell.execute_reply":"2021-11-18T09:34:10.499706Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}